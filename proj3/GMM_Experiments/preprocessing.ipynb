{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "## extract features and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute short time Fourier transformation (STFT).\n",
    "def stft(sig, nfft, win_length_time, hop_length_time, fs, window_type='hann'):\n",
    "    win_sample = int(win_length_time * fs)\n",
    "    hop_sample = int(hop_length_time * fs)\n",
    "\n",
    "    if window_type == 'hann':\n",
    "        window = np.hanning(win_sample)\n",
    "    elif window_type == 'hamming':\n",
    "        window = np.hamming(win_sample)\n",
    "    else:\n",
    "        print('Wrong window type : {}'.format(window_type))\n",
    "        raise StopIteration\n",
    "        \n",
    "    n_frames = int(np.floor((len(sig) - win_sample) / float(hop_sample)) + 1)\n",
    "    frames = np.stack([window * sig[step*hop_sample : step*hop_sample + win_sample] for step in range(n_frames)])\n",
    "    \n",
    "    stft = np.fft.rfft(frames, n = nfft, axis=1)\n",
    "    return stft\n",
    "\n",
    "# Obtain mel-scale filterbank.\n",
    "def get_melfb(sr, nfft, n_mels):\n",
    "    mel_fb = librosa.filters.mel(sr, n_fft=nfft, n_mels=n_mels)\n",
    "    return mel_fb\n",
    "\n",
    "# Compute log mel spectrogram.\n",
    "def compute_log_melspectrogram(spec, sr, nfft, n_mels):\n",
    "    eps = sys.float_info.epsilon    \n",
    "    mel_fb = get_melfb(sr, nfft, n_mels)\n",
    "    power_spec = spec**2\n",
    "    mel_spec = np.matmul(power_spec, mel_fb.transpose())\n",
    "    mel_spec = 10*np.log10(mel_spec+eps)\n",
    "    return mel_spec\n",
    "\n",
    "# Compute MFCC.\n",
    "def compute_mfcc(spec, sr, nfft, n_mels,n_mfcc):\n",
    "    mel_spec = compute_log_melspectrogram(spec,sr, nfft, n_mels)\n",
    "    mfcc = scipy.fftpack.dct(mel_spec, axis=-1, norm='ortho')\n",
    "    return mfcc[:,:n_mfcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_list, spk_list, sr, nfft, window_len, hop_len, \n",
    "                 path='./', win_type='hann', feature_type='fft', n_coeff=64, n_mfcc=13):\n",
    "    list_x=[]\n",
    "    list_y=[]\n",
    "    for data in data_list:\n",
    "        sig,_ = librosa.load(data, sr=sr)\n",
    "        feature = stft(sig, nfft, window_len, hop_len, sr, window_type=win_type)\n",
    "        feature = abs(feature)\n",
    "        if feature_type == 'mel':\n",
    "            feature = compute_log_melspectrogram(feature, sr, nfft, n_coeff)\n",
    "        elif feature_type == 'mfcc':\n",
    "            feature = compute_mfcc(feature, sr, nfft, n_coeff, n_mfcc)\n",
    "        label = spk_list.index(data.split('/')[-1].split('\\\\')[-1].split('_')[0])\n",
    "        list_x.append(feature)\n",
    "        list_y.append(label)\n",
    "    list_x = np.array(list_x)\n",
    "    list_y = np.array(list_y)\n",
    "    np.savez(path, x=list_x, y=list_y)\n",
    "    print(len(list_x), len(list_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = glob.glob('../SpeakerDB/Train/*_train.wav')\n",
    "test_list = glob.glob('../SpeakerDB/Test/*_test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_list = [train_list[i].split('/')[-1].split('\\\\')[-1].split('_')[0] for i in range(len(train_list))]\n",
    "with open('GMM_speakers.txt','w') as f:\n",
    "    for spk in speaker_list:\n",
    "        f.write(spk+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset(train_list, speaker_list, 16000, 1024, 0.025, 0.01, \n",
    "                       path='./gmm_tr_data_j.npz',feature_type='mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset(test_list, speaker_list, 16000, 1024, 0.025, 0.01, \n",
    "                       path='./gmm_test_data_j.npz',feature_type='mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
